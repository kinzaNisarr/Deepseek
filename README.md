# **ğŸ§  DeepSeek Chatbot**  
ğŸš€ **AI-Powered Coding Assistant** using **DeepSeek** models via **Ollama** & **LangChain**  

## **ğŸ“Œ Overview**  
This project implements an **AI chatbot** that assists with **coding, debugging, and solution design** using **DeepSeek models (1.5B & 7B parameters)**. The chatbot is built with **Streamlit**, integrates with **Ollama**, and leverages **LangChain** for AI-driven conversations.  

## **âš™ï¸ Features**  
âœ… **Runs Locally** â€“ No external API needed.  
âœ… **Code Debugging** â€“ AI suggests debugging strategies.  
âœ… **Python Expertise** â€“ AI helps with Python solutions.  
âœ… **Interactive Chat** â€“ Streamed responses for better UX.  
âœ… **Customizable** â€“ Choose between **DeepSeek 1.5B & 7B** models.  

## **ğŸ“¥ Installation**  

### **1ï¸âƒ£ Install Ollama**  
Ollama is required to run DeepSeek models locally.  

**For macOS & Linux:**  
```bash
curl -fsSL https://ollama.com/install.sh | sh
```
**For Windows:**  
[Download & Install Ollama](https://ollama.com/download)  

Verify installation:  
```bash
ollama --version
```

---

### **2ï¸âƒ£ Download DeepSeek Model**  
Run the following command to pull the DeepSeek model:  
```bash
ollama pull deepseek-coder:1.5b
```
or  
```bash
ollama pull deepseek-coder:7b
```

To check available models:  
```bash
ollama list
```

---

### **3ï¸âƒ£ Install Python Dependencies**  
Make sure you have Python **3.8+** installed. Then install dependencies:  

```bash
pip install -r requirements.txt
```
_(If `requirements.txt` is not available, install manually)_  
```bash
pip install streamlit langchain-core langchain_ollama
```

---

### **4ï¸âƒ£ Run the Chatbot Locally**  
Once everything is installed, start the chatbot with:  

```bash
streamlit run app.py
```

The chatbot will open in your **web browser**, ready to assist with coding!

---

## **ğŸ“¡ API Usage (Optional)**  
If you want to use DeepSeek via API, first start the Ollama server:  

```bash
ollama serve
```

Then send a request using Python:  
```python
import requests

url = "http://localhost:11434/api/generate"
data = {
    "model": "deepseek-coder:1.5b",
    "prompt": "Explain recursion in Python",
    "stream": False
}

response = requests.post(url, json=data)
print(response.json())
```

---

## **ğŸ› ï¸ Project Structure**  

```
ğŸ“‚ deepseek-chatbot
 â”œâ”€â”€ app.py                # Streamlit chatbot application
 â”œâ”€â”€ requirements.txt       # Python dependencies
 â”œâ”€â”€ README.md              # Project documentation (this file)
```

---

## **ğŸš€ Future Enhancements**  
ğŸ”¹ **Add more DeepSeek models**  
ğŸ”¹ **Improve UI with advanced formatting**  
ğŸ”¹ **Integrate with databases for chat history storage**  

---

## **ğŸ“œ License**  
This project is **open-source** under the **MIT License**.  

---

## **ğŸ“¬ Contact**  
For questions or contributions, reach out via GitHub or email at kinzanisar9@gmail.com.  

